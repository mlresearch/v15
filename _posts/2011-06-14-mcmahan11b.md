---
title: 'Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and
  L1 Regularization'
abstract: We prove that many mirror descent algorithms for online convex optimization
  (such as online gradient descent) have an equivalent interpretation as follow-the-regularized-leader
  (FTRL) algorithms. This observation makes the relationships between many commonly
  used algorithms explicit, and provides theoretical insight on previous experimental
  observations.  In particular, even though the FOBOS composite mirror descent algorithm
  handles L1 regularization explicitly, it has been observed that the FTRL-style Regularized
  Dual Averaging (RDA) algorithm is even more effective at producing sparsity.  Our
  results demonstrate that the key difference between these algorithms is how they
  handle the cumulative L1 penalty. While FOBOS handles the L1 term exactly on any
  given update, we show that it is effectively using subgradient approximations to
  the L1 penalty from previous rounds, leading to less sparsity than RDA, which handles
  the cumulative penalty in closed form.  The FTRL-Proximal algorithm, which we introduce,
  can be seen as a hybrid of these two algorithms, and significantly outperforms both
  on a large, real-world dataset.   [pdf]
pdf: http://proceedings.pmlr.press/mcmahan11b/mcmahan11b.pdf
layout: inproceedings
id: mcmahan11b
month: 0
firstpage: 525
lastpage: 533
page: 525-533
origpdf: http://jmlr.org/proceedings/papers/v15/mcmahan11b/mcmahan11b.pdf
sections: 
author:
- given: Brendan
  family: McMahan
date: 2011-06-14
publisher: PMLR
container-title: Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics
volume: '15'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 6
  - 14
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
