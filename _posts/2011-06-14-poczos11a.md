---
title: On the Estimation of $\alpha$-Divergences
abstract: We propose new nonparametric, consistent Rényi-$\alpha$ and Tsallis-$\alpha$ divergence
  estimators for continuous distributions. Given two independent and identically distributed
  samples, a ‘brute force’ approach would be simply to estimate the underlying densities,
  and plug these densities into the corresponding formulas. However, it is not our
  goal to consistently estimate these possibly high dimensional densities, and our
  algorithm avoids estimating them. We will use simple $k$-nearest-neighbor statistics,
  and interestingly enough, we will still be able to prove
  that the proposed divergence estimators are consistent under certain conditions.
  We will also show how to use them for mutual information estimation, and demonstrate
  their efficiency by some numerical experiments.
pdf: http://proceedings.mlr.press/v15/poczos11a/poczos11a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: poczos11a
month: 0
tex_title: On the Estimation of $\alpha$-Divergences
firstpage: 609
lastpage: 617
page: 609-617
order: 609
cycles: false
author:
- given: Barnabas
  family: Poczos
- given: Jeff
  family: Schneider
date: 2011-06-14
address: Fort Lauderdale, FL, USA
publisher: PMLR
container-title: Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics
volume: '15'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 6
  - 14
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
