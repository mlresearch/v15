---
title: Learning mixtures of Gaussians with maximum-a-posteriori oracle
abstract: We consider the problem of estimating the parameters of a mixture of distributions,
  where each component distribution is from a given parametric family e.g. exponential,
  Gaussian etc. We define a learning model in which the learner has access to a “maximum-a-posteriori”
  oracle which given any sample from a mixture of distributions, tells the learner
  which component distribution was the most likely to have generated it. We describe
  a learning algorithm in this setting which accurately estimates the parameters of
  a mixture of $k$ spherical Gaussians in $\mathbb{R}^d$ assuming the component Gaussians satisfy
  a mild separation condition. Our algorithm uses only polynomially many (in $d, k$)
  samples and oracle calls, and our separation condition is much weaker than those
  required by unsupervised learning algorithms like [Arora 01, Vempala 02].
pdf: http://proceedings.mlr.press/v15/mahalanabis11a/mahalanabis11a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mahalanabis11a
month: 0
tex_title: Learning mixtures of Gaussians with maximum-a-posteriori oracle
firstpage: 489
lastpage: 497
page: 489-497
order: 489
cycles: false
author:
- given: Satyaki
  family: Mahalanabis
date: 2011-06-14
address: Fort Lauderdale, FL, USA
publisher: PMLR
container-title: Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics
volume: '15'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 6
  - 14
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
