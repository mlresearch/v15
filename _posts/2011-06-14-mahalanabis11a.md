---
title: Learning mixtures of Gaussians with maximum-a-posteriori oracle
abstract: We consider the problem of estimating the parameters of a mixture of distributions,
  where each component distribution is from a given parametric family e.g. exponential,
  Gaussian etc. We define a learning model in which the learner has access to a “maximum-a-posteriori”
  oracle which given any sample from a mixture of distributions, tells the learner
  which component distribution was the most likely to have generated it. We describe
  a learning algorithm in this setting which accurately estimates the parameters of
  a mixture of k spherical Gaussians in R^d assuming the component Gaussians satisfy
  a mild separation condition. Our algorithm uses only polynomially many (in d, k)
  samples and oracle calls, and our separation condition is much weaker than those
  required by unsupervised learning algorithms like [Arora 01, Vempala 02]. [pdf]
pdf: http://proceedings.mlr.press/v15/mahalanabis11a/mahalanabis11a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mahalanabis11a
month: 0
firstpage: 489
lastpage: 497
page: 489-497
sections: 
author:
- given: Satyaki
  family: Mahalanabis
date: 2011-06-14
address: Fort Lauderdale, FL, USA
publisher: PMLR
container-title: Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics
volume: '15'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 6
  - 14
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
